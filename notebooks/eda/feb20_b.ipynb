{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md_title",
   "metadata": {},
   "source": [
    "# Nearmap AI Feature Extraction \u2014 Parcel-Level Enrichment\n",
    "\n",
    "This notebook processes the USC Nearmap sample imagery and AI-detection layers to produce a **parcel-level feature table** for the Hidden-Housing study area.\n",
    "\n",
    "**Pipeline overview**\n",
    "\n",
    "| Step | Description |\n",
    "|------|-------------|\n",
    "| 1 | Load Nearmap building footprints and AI feature layers |\n",
    "| 2 | Load LA City administrative data (landbase, assessor, LARIAC) |\n",
    "| 3 | Reproject all layers to a common CRS (EPSG:2229) |\n",
    "| 4 | Estimate and correct a systematic spatial offset in the Nearmap data |\n",
    "| 5 | Compute per-parcel area coverage for buildings and each AI feature |\n",
    "| 6 | Attach assessor attributes (property type, year built, units, etc.) |\n",
    "| 7 | Save the enriched parcel table to GeoPackage |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_step1",
   "metadata": {},
   "source": [
    "## Step 1 \u2014 Load Nearmap Data\n",
    "\n",
    "Load the Nearmap tile boundary (used as the study-area mask) and building-footprint layer. Tile boundaries are in EPSG:3857; everything will be reprojected later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc41387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\nimport glob, re, os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom shapely.affinity import translate\nfrom sklearn.neighbors import BallTree\n\nfrom src.geoadmin import load_laraic, get_landbase_bymask, load_assessor_parcels_bygeom\n\nos.chdir('../..')\n\n# \u2500\u2500 Paths \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nNEARMAP_DIR  = '/Users/adamswietek/Downloads/USC_Nearmap_Sample_Data'\nNEARMAP_TILE = f'{NEARMAP_DIR}/IMAGERY_SAMPLE_EPSG3857_Date20251005/Tiles.shp'\nNEARMAP_AI   = f'{NEARMAP_DIR}/AI_SAMPLE'\nNEARMAP_BLDG = f'{NEARMAP_AI}/ai_features_None_Building.gpkg'\n\nnearmap_building = gpd.read_file(NEARMAP_BLDG)\nnearmap_tile     = gpd.read_file(NEARMAP_TILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_step1b",
   "metadata": {},
   "source": [
    "### Discover AI Feature Layers\n",
    "\n",
    "Scan the AI sample directory for all per-feature GeoPackage files. The `_Building` layer is handled separately (loaded above); the remaining 20 layers (roof type, condition flags, tree overhang, etc.) are processed in bulk in Step 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8989b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_files = sorted(glob.glob(f'{NEARMAP_AI}/ai_features_None_*.gpkg'))\nskip = re.compile(r'_Building.*|_Deprecated.*', re.IGNORECASE)\nlayer_files = [f for f in layer_files if not skip.search(os.path.basename(f))]\n\ndef layer_name(path):\n    \"\"\"ai_features_None_Roof_Rusting.gpkg  \u2192  roof_rusting\"\"\"\n    name = os.path.basename(path).replace('ai_features_None_', '').replace('.gpkg', '')\n    return name.lower().replace('-', '_')\n\nai_cols = [layer_name(f) for f in layer_files]\nprint(f\"Found {len(layer_files)} AI feature layers:\")\nfor col in ai_cols:\n    print(f\"  {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_step2",
   "metadata": {},
   "source": [
    "## Step 2 \u2014 Load LA City Administrative Data\n",
    "\n",
    "Three datasets are loaded for the study area, clipped to the Nearmap tile footprint:\n",
    "\n",
    "- **Landbase** \u2014 parcel polygons with a stable `ASSETID` key\n",
    "- **Assessor** (APD) \u2014 roll-year attributes: property type, year built, units, value, etc.\n",
    "- **LARIAC** \u2014 building footprints derived from aerial lidar (used for height / area reference)\n",
    "\n",
    "All three are loaded for the 2020 roll year, which best matches the Nearmap imagery date (Oct 2025 imagery; 2020 is the most recent available assessor snapshot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8581018",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANDBASE_YR = 2020\nASSESSOR_YR = 2020\nLARIAC_YR   = 2020\n\ndef load_data_by_year(neighborhood, lb_yr, apd_yr, lar_yr, source='lariac'):\n    landbase_parcels = get_landbase_bymask(neighborhood, lb_yr)\n\n    polygon_geometry = neighborhood.to_crs(4326).iloc[0].geometry\n    assessor_data = load_assessor_parcels_bygeom(polygon_geometry)\n    assessor_data = assessor_data.loc[assessor_data.RollYear == apd_yr]\n    assessor_data = assessor_data.to_crs(landbase_parcels.crs)\n\n    if source == 'lariac':\n        lariac_structures = load_laraic(neighborhood, lar_yr)\n        lariac_structures = lariac_structures.to_crs(landbase_parcels.crs)\n\n    return landbase_parcels, assessor_data, lariac_structures\n\naoi = nearmap_tile.dissolve()\nlandbase, assessor, lariac = load_data_by_year(\n    aoi, lb_yr=LANDBASE_YR, apd_yr=ASSESSOR_YR, lar_yr=LARIAC_YR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_step3",
   "metadata": {},
   "source": [
    "## Step 3 \u2014 Prepare Data Slices and Reproject\n",
    "\n",
    "Slim each dataset down to the columns needed downstream, then reproject the Nearmap building footprints from EPSG:3857 to the landbase CRS (EPSG:2229 \u2014 NAD83 California State Plane Zone V, US survey feet). All subsequent spatial operations use this projected CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a47d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb  = landbase[['ASSETID', 'geometry']].copy()\nasr = assessor.copy()\nlar = lariac.dropna(subset=['HEIGHT'])[['BLD_ID', 'AREA', 'geometry']].copy()\n\n# Reproject Nearmap buildings to the landbase CRS (EPSG:2229, NAD83 California zone 5 ft-US)\nnm_proj = (nearmap_building[['id', 'areaSqft', 'clippedAreaSqft', 'geometry']]\n           .copy()\n           .to_crs(lb.crs))\nprint(f\"nm_proj: {len(nm_proj):,} buildings  |  CRS: {nm_proj.crs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_step4",
   "metadata": {},
   "source": [
    "## Step 4 \u2014 Estimate and Correct Spatial Offset\n",
    "\n",
    "Nearmap AI features are often shifted slightly relative to authoritative parcel boundaries due to differences in georeferencing. We estimate the shift by:\n",
    "\n",
    "1. Computing centroids for all Nearmap buildings and all landbase parcels.\n",
    "2. Finding the nearest-neighbour landbase parcel for each Nearmap building (pairs farther than 200 ft are discarded).\n",
    "3. Taking the **median** centroid displacement as the correction offset.\n",
    "\n",
    "The same `(OFFSET_X, OFFSET_Y)` is then applied to the building footprints **and** every AI feature layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714b251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the systematic spatial shift between Nearmap buildings and landbase parcel centroids\n# using nearest-neighbour matching. Only pairs within 200 ft are used to exclude bad matches.\nlb_xy = np.column_stack([lb.geometry.centroid.x, lb.geometry.centroid.y])\nnm_xy = np.column_stack([nm_proj.geometry.centroid.x, nm_proj.geometry.centroid.y])\n\ntree = BallTree(lb_xy)\ndist, idx = tree.query(nm_xy, k=1)\n\nmask = dist[:, 0] < 200   # within 200 ft\ndx = lb_xy[idx[mask, 0], 0] - nm_xy[mask, 0]\ndy = lb_xy[idx[mask, 0], 1] - nm_xy[mask, 1]\n\nOFFSET_X = float(np.median(dx))\nOFFSET_Y = float(np.median(dy))\n\nprint(f\"Pairs used : {mask.sum()}\")\nprint(f\"  dx  mean={dx.mean():.2f}  median={OFFSET_X:.2f}  std={dx.std():.2f}  ft\")\nprint(f\"  dy  mean={dy.mean():.2f}  median={OFFSET_Y:.2f}  std={dy.std():.2f}  ft\")\nprint(f\"\\nApplied offset  \u2192  dx={OFFSET_X:.2f} ft,  dy={OFFSET_Y:.2f} ft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fc84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise a 500 ft buffer around the first building to inspect the correction\nsample_pt = nm_proj.geometry.iloc[0].centroid\nbuf = 500\nxmin, ymin, xmax, ymax = sample_pt.x-buf, sample_pt.y-buf, sample_pt.x+buf, sample_pt.y+buf\n\nnm_aligned_viz = nm_proj.copy()\nnm_aligned_viz.geometry = nm_aligned_viz.geometry.translate(xoff=OFFSET_X, yoff=OFFSET_Y)\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 8))\nfor ax, nm_plot, title in zip(\n    axes,\n    [nm_proj.cx[xmin:xmax, ymin:ymax],\n     nm_aligned_viz.cx[xmin:xmax, ymin:ymax]],\n    ['Before correction', f'After correction  (dx={OFFSET_X:.1f} ft, dy={OFFSET_Y:.1f} ft)']\n):\n    lb.cx[xmin:xmax, ymin:ymax].plot(ax=ax, facecolor='none', edgecolor='black', linewidth=1.5)\n    nm_plot.plot(ax=ax, facecolor='steelblue', alpha=0.4, edgecolor='steelblue', linewidth=1)\n    ax.set_xlim(xmin, xmax); ax.set_ylim(ymin, ymax)\n    ax.set_title(title, fontsize=12)\nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdfc3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the offset to all Nearmap buildings \u2014 this is the authoritative aligned layer\nnm = nm_proj.copy()\nnm.geometry = nm.geometry.translate(xoff=OFFSET_X, yoff=OFFSET_Y)\nnm = nm[['id', 'areaSqft', 'clippedAreaSqft', 'geometry']]\nprint(f\"nm (aligned): {len(nm):,} buildings  |  CRS: {nm.crs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_step5",
   "metadata": {},
   "source": [
    "## Step 5 \u2014 Extract Parcel-Level Features\n",
    "\n",
    "For each aligned layer (buildings + 20 AI features):\n",
    "\n",
    "1. **Dissolve** all polygons into a single geometry (avoids double-counting overlapping detections).\n",
    "2. **Overlay** (intersection) with the landbase parcel grid.\n",
    "3. Sum the intersection area per `ASSETID` to get the **square footage** of that feature within each parcel.\n",
    "\n",
    "The result is one row per parcel with columns `nm_bldg_sqft`, `roof`, `gable`, `shingle`, `structural_damage`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9286e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dissolve aligned building footprints into a single geometry, then intersect with each parcel.\n# The intersection area gives the square footage of Nearmap building coverage per parcel.\nnm_diss = nm[['geometry']].dissolve()\nnm_over = gpd.overlay(nm_diss, lb[['ASSETID', 'geometry']], how='intersection')\nnm_over['nm_bldg_sqft'] = nm_over.geometry.area\n\nparcel_features = nm_over[['ASSETID', 'nm_bldg_sqft', 'geometry']].copy()\nprint(f\"Parcels with Nearmap building coverage: {len(parcel_features):,}\")\n\n# For each AI feature layer: apply the same spatial offset, dissolve, overlay, and compute area.\nprint(\"\\nProcessing AI feature layers...\")\nfor fpath in layer_files:\n    col = layer_name(fpath)\n    layer = gpd.read_file(fpath)[['geometry']].to_crs(lb.crs)\n    layer.geometry = layer.geometry.translate(xoff=OFFSET_X, yoff=OFFSET_Y)\n    layer_diss = layer.dissolve()\n    layer_over = gpd.overlay(layer_diss, lb[['ASSETID', 'geometry']], how='intersection')\n    layer_over[col] = layer_over.geometry.area\n    agg = layer_over.groupby('ASSETID')[col].sum().reset_index()\n    parcel_features = parcel_features.merge(agg, on='ASSETID', how='left')\n    n = parcel_features[col].notna().sum()\n    print(f\"  {col:<45}  {n:>4} parcels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_step6",
   "metadata": {},
   "source": [
    "## Step 6 \u2014 Attach Assessor Attributes\n",
    "\n",
    "Spatially join the assessor parcel data to the landbase parcel grid, then merge those attributes into the Nearmap feature table on `ASSETID`. This adds property-level information (AIN, property type, year built, square footage, number of units, assessed value, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfe1c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial join of landbase parcels with assessor parcel data.\n# A small buffer(0) is applied to landbase geometries to fix any invalid geometry issues.\nlb['geometry'] = lb.buffer(0)\nparcel_asr = (gpd.sjoin(lb, asr, how='left', predicate='intersects')\n                 .drop(columns=['index_right', 'geometry'], errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324375bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcel_features = parcel_features.merge(parcel_asr, on='ASSETID', how='left')\n\n# Normalise AIN column name (case-insensitive lookup)\nain_col = next((c for c in parcel_features.columns if c.upper() == 'AIN'), None)\nif ain_col and ain_col != 'AIN':\n    parcel_features = parcel_features.rename(columns={ain_col: 'AIN'})\n\nprint(f\"parcel_features: {len(parcel_features):,} rows\")\nprint(f\"  with AIN         : {parcel_features['AIN'].notna().sum():,}\")\nprint(f\"  with nm_bldg_sqft: {parcel_features['nm_bldg_sqft'].notna().sum():,}\")\nparcel_features[['ASSETID', 'AIN', 'nm_bldg_sqft'] + ai_cols].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_step7",
   "metadata": {},
   "source": [
    "## Step 7 \u2014 Save Outputs\n",
    "\n",
    "Write the enriched parcel table and the assessor data to GeoPackage files in `data/processed/` for downstream modelling and mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df92397",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr.to_file('data/processed/asr.gpkg')\nparcel_features.to_file('data/processed/nm_parcel_joined.gpkg')\nprint(\"Saved:\"  )\nprint(\"  data/processed/asr.gpkg\")\nprint(\"  data/processed/nm_parcel_joined.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_step8",
   "metadata": {},
   "source": [
    "## Step 8 \u2014 Preview Final Dataset\n",
    "\n",
    "Quick sanity check on the final parcel table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at key attributes in the final parcel table\nparcel_features[['ASSETID', 'AIN', 'RollYear', 'PropertyType', 'YearBuilt',\n                 'SQFTmain', 'Units', 'nm_bldg_sqft'] + ai_cols].head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}